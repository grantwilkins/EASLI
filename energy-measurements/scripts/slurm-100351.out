environment: line 5: __conda_exe: command not found
environment: line 5: __conda_exe: command not found
environment: line 5: __conda_exe: command not found
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-06-19 18:48:59,627] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
[2024-06-19 18:49:47,451] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-19 18:49:47,451] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-06-19 18:49:47,684] [INFO] [engine_v2.py:82:__init__] Building model...
Using /gpfs/fs1/home/ac.gwilkins/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
slurmstepd: error: *** JOB 100351 ON gpu5 CANCELLED AT 2024-06-19T19:33:27 ***

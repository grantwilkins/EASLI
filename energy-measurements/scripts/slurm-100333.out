environment: line 5: __conda_exe: command not found
environment: line 5: __conda_exe: command not found
[2024-06-19 16:31:07,514] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
[2024-06-19 16:31:38,064] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-06-19 16:31:38,065] [INFO] [runner.py:568:main] cmd = /home/ac.gwilkins/.conda/envs/mii/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None mii-inference.py --out_dir ./llama2-13b/2024-06-19/16-29-58 --hf_name /lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496 --dataset alpaca
[2024-06-19 16:32:50,871] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-06-19 16:33:18,333] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2024-06-19 16:33:18,333] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-06-19 16:33:18,333] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-06-19 16:33:18,333] [INFO] [launch.py:164:main] dist_world_size=1
[2024-06-19 16:33:18,333] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-06-19 16:33:18,336] [INFO] [launch.py:256:main] process 1657081 spawned with command: ['/home/ac.gwilkins/.conda/envs/mii/bin/python', '-u', 'mii-inference.py', '--local_rank=0', '--out_dir', './llama2-13b/2024-06-19/16-29-58', '--hf_name', '/lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496', '--dataset', 'alpaca']
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-06-19 16:35:09,371] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
[2024-06-19 16:35:29,362] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-19 16:35:29,363] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use).
[W socket.cpp:464] [c10d] The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).
[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/gpfs/fs1/home/ac.gwilkins/EASLI/energy-measurements/mii-inference.py", line 107, in <module>
    pipe = mii.pipeline(hf_name)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/api.py", line 207, in pipeline
    inference_engine = load_model(model_config)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/modeling/models.py", line 14, in load_model
    init_distributed(model_config)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/utils.py", line 187, in init_distributed
    deepspeed.init_distributed(dist_backend="nccl", timeout=timedelta(seconds=1e9))
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 670, in init_distributed
    cdb = TorchBackend(dist_backend, timeout, init_method, rank, world_size)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 112, in __init__
    self.init_process_group(backend, timeout, init_method, rank, world_size)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 142, in init_process_group
    torch.distributed.init_process_group(backend,
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 89, in wrapper
    func_return = func(*args, **kwargs)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1305, in init_process_group
    store, rank, world_size = next(rendezvous_iterator)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/rendezvous.py", line 246, in _env_rendezvous_handler
    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/rendezvous.py", line 174, in _create_c10d_store
    return TCPStore(
torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).
[2024-06-19 16:35:33,477] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 1657081
[2024-06-19 16:35:33,477] [ERROR] [launch.py:325:sigkill_handler] ['/home/ac.gwilkins/.conda/envs/mii/bin/python', '-u', 'mii-inference.py', '--local_rank=0', '--out_dir', './llama2-13b/2024-06-19/16-29-58', '--hf_name', '/lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496', '--dataset', 'alpaca'] exits with return code = 1
[2024-06-19 16:36:50,713] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
[2024-06-19 16:37:15,095] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-06-19 16:37:15,096] [INFO] [runner.py:568:main] cmd = /home/ac.gwilkins/.conda/envs/mii/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None mii-inference.py --out_dir ./llama2-13b/2024-06-19/16-35-34 --hf_name /lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496 --dataset self-oss
[2024-06-19 16:38:34,320] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-06-19 16:38:59,442] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2024-06-19 16:38:59,442] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-06-19 16:38:59,443] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-06-19 16:38:59,443] [INFO] [launch.py:164:main] dist_world_size=1
[2024-06-19 16:38:59,443] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-06-19 16:38:59,445] [INFO] [launch.py:256:main] process 1662651 spawned with command: ['/home/ac.gwilkins/.conda/envs/mii/bin/python', '-u', 'mii-inference.py', '--local_rank=0', '--out_dir', './llama2-13b/2024-06-19/16-35-34', '--hf_name', '/lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496', '--dataset', 'self-oss']
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-06-19 16:41:07,680] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
[2024-06-19 16:41:36,431] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-19 16:41:36,431] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use).
[W socket.cpp:464] [c10d] The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).
[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/gpfs/fs1/home/ac.gwilkins/EASLI/energy-measurements/mii-inference.py", line 107, in <module>
    pipe = mii.pipeline(hf_name)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/api.py", line 207, in pipeline
    inference_engine = load_model(model_config)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/modeling/models.py", line 14, in load_model
    init_distributed(model_config)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/utils.py", line 187, in init_distributed
    deepspeed.init_distributed(dist_backend="nccl", timeout=timedelta(seconds=1e9))
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 670, in init_distributed
    cdb = TorchBackend(dist_backend, timeout, init_method, rank, world_size)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 112, in __init__
    self.init_process_group(backend, timeout, init_method, rank, world_size)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 142, in init_process_group
    torch.distributed.init_process_group(backend,
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 89, in wrapper
    func_return = func(*args, **kwargs)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1305, in init_process_group
    store, rank, world_size = next(rendezvous_iterator)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/rendezvous.py", line 246, in _env_rendezvous_handler
    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/rendezvous.py", line 174, in _create_c10d_store
    return TCPStore(
torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).
[2024-06-19 16:41:38,610] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 1662651
[2024-06-19 16:41:38,610] [ERROR] [launch.py:325:sigkill_handler] ['/home/ac.gwilkins/.conda/envs/mii/bin/python', '-u', 'mii-inference.py', '--local_rank=0', '--out_dir', './llama2-13b/2024-06-19/16-35-34', '--hf_name', '/lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496', '--dataset', 'self-oss'] exits with return code = 1
[2024-06-19 16:42:48,702] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
[2024-06-19 16:43:13,003] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-06-19 16:43:13,004] [INFO] [runner.py:568:main] cmd = /home/ac.gwilkins/.conda/envs/mii/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None mii-inference.py --out_dir ./llama2-13b/2024-06-19/16-41-39 --hf_name /lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496 --dataset orca
[2024-06-19 16:44:33,420] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-06-19 16:45:00,546] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2024-06-19 16:45:00,546] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-06-19 16:45:00,546] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-06-19 16:45:00,546] [INFO] [launch.py:164:main] dist_world_size=1
[2024-06-19 16:45:00,546] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-06-19 16:45:00,548] [INFO] [launch.py:256:main] process 1668750 spawned with command: ['/home/ac.gwilkins/.conda/envs/mii/bin/python', '-u', 'mii-inference.py', '--local_rank=0', '--out_dir', './llama2-13b/2024-06-19/16-41-39', '--hf_name', '/lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496', '--dataset', 'orca']
/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-06-19 16:47:10,246] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible
[2024-06-19 16:47:42,594] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-19 16:47:42,596] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use).
[W socket.cpp:464] [c10d] The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).
[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/gpfs/fs1/home/ac.gwilkins/EASLI/energy-measurements/mii-inference.py", line 107, in <module>
    pipe = mii.pipeline(hf_name)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/api.py", line 207, in pipeline
    inference_engine = load_model(model_config)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/modeling/models.py", line 14, in load_model
    init_distributed(model_config)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/mii/utils.py", line 187, in init_distributed
    deepspeed.init_distributed(dist_backend="nccl", timeout=timedelta(seconds=1e9))
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 670, in init_distributed
    cdb = TorchBackend(dist_backend, timeout, init_method, rank, world_size)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 112, in __init__
    self.init_process_group(backend, timeout, init_method, rank, world_size)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 142, in init_process_group
    torch.distributed.init_process_group(backend,
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 89, in wrapper
    func_return = func(*args, **kwargs)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1305, in init_process_group
    store, rank, world_size = next(rendezvous_iterator)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/rendezvous.py", line 246, in _env_rendezvous_handler
    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)
  File "/home/ac.gwilkins/.conda/envs/mii/lib/python3.10/site-packages/torch/distributed/rendezvous.py", line 174, in _create_c10d_store
    return TCPStore(
torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).
[2024-06-19 16:47:44,716] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 1668750
[2024-06-19 16:47:44,717] [ERROR] [launch.py:325:sigkill_handler] ['/home/ac.gwilkins/.conda/envs/mii/bin/python', '-u', 'mii-inference.py', '--local_rank=0', '--out_dir', './llama2-13b/2024-06-19/16-41-39', '--hf_name', '/lcrc/project/ECP-EZ/ac.gwilkins/models--meta-llama--Llama-2-13b-chat-hf/snapshots/c2f3ec81aac798ae26dcc57799a994dfbf521496', '--dataset', 'orca'] exits with return code = 1

1718787612.5205426,tokenizer,0.16879487037658691,10081,0,0,Llama-2-7b-chat-hf,1,startup,0,32,43,Flash-Attention-2,alpaca,40960.0,13897.6875
1718787612.6893375,model load,44.267011642456055,2456313,0,0,Llama-2-7b-chat-hf,1,startup,0,32,43,Flash-Attention-2,alpaca,40960.0,13897.6875
1718787716.5553226,tokenizer,0.1756575107574463,10094,0,0,Llama-2-7b-chat-hf,1,startup,0,32,170,Flash-Attention-2,alpaca,40960.0,13897.6875
1718787716.7309802,model load,45.401156187057495,2525168,0,0,Llama-2-7b-chat-hf,1,startup,0,32,170,Flash-Attention-2,alpaca,40960.0,13897.6875
1718788247.5407424,tokenizer,0.21622276306152344,10078,0,0,Llama-2-7b-chat-hf,1,startup,0,32,42,Flash-Attention-2,alpaca,40960.0,13897.6875
1718788247.7569652,model load,47.22172403335571,2621834,0,0,Llama-2-7b-chat-hf,1,startup,0,32,42,Flash-Attention-2,alpaca,40960.0,13897.6875
1718788295.0072114,start-inference-0,8.33067798614502,952574,10,0,Llama-2-7b-chat-hf,1,Give three,197,207,32,170,Flash-Attention-2,alpaca,40960.0,14363.6875
1718788303.345736,start-inference-1,2.014256715774536,277730,8,1,Llama-2-7b-chat-hf,1,What are t,66,74,32,170,Flash-Attention-2,alpaca,40960.0,14363.6875
1718788305.3677306,start-inference-2,8.136352300643921,1134138,9,2,Llama-2-7b-chat-hf,1,Describe t,266,275,32,170,Flash-Attention-2,alpaca,40960.0,14445.6875
1718788313.5130215,start-inference-3,9.976158142089844,1397971,9,3,Llama-2-7b-chat-hf,1,How can we,326,335,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788323.4985814,start-inference-4,3.246863603591919,452451,14,4,Llama-2-7b-chat-hf,1,Describe a,101,115,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788326.752468,start-inference-5,1.3418636322021484,182338,16,5,Llama-2-7b-chat-hf,1,Identify t,44,60,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788328.101014,start-inference-6,5.823740720748901,817591,18,6,Llama-2-7b-chat-hf,1,Explain wh,190,208,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788333.9316578,start-inference-7,10.465807437896729,1476629,23,7,Llama-2-7b-chat-hf,1,Write a sh,342,365,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788344.40447,start-inference-8,2.7396528720855713,379563,10,8,Llama-2-7b-chat-hf,1,Render a 3,90,100,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788347.1518598,start-inference-9,0.8547050952911377,126822,25,9,Llama-2-7b-chat-hf,1,Evaluate t,28,53,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788348.0125291,start-inference-10,5.157336950302124,721610,8,10,Llama-2-7b-chat-hf,1,How did Ju,169,177,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788353.176878,start-inference-11,0.2772085666656494,41636,8,11,Llama-2-7b-chat-hf,1,What is th,9,17,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
1718788353.4612906,start-inference-12,5.930562257766724,827356,17,12,Llama-2-7b-chat-hf,1,Generate a,189,206,32,170,Flash-Attention-2,alpaca,40960.0,14525.6875
